<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/Phoenix-Logo-16B.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/Phoenix-Logo-16B.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Mueller, David, Nicholas Andrews, and Mark Dredze. &quot;Sources of transfer in multilingual named entity recognition.&quot; arXiv preprint arXiv:2005.00847 (2020).  命名实体本质上是多语言的，任何给定语言的注释都可能受到限制。这促使我们考虑多语言命名实">
<meta property="og:type" content="article">
<meta property="og:title" content="阅读《Sources of Transfer in Multilingual NER》">
<meta property="og:url" content="http://example.com/2022/05/06/%E9%98%85%E8%AF%BB%E3%80%8ASource-of-Transfer-in-Multilingual-NER%E3%80%8B/index.html">
<meta property="og:site_name" content="Sycamore">
<meta property="og:description" content="Mueller, David, Nicholas Andrews, and Mark Dredze. &quot;Sources of transfer in multilingual named entity recognition.&quot; arXiv preprint arXiv:2005.00847 (2020).  命名实体本质上是多语言的，任何给定语言的注释都可能受到限制。这促使我们考虑多语言命名实">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062241917.png">
<meta property="og:image" content="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062328986.png">
<meta property="og:image" content="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062331071.png">
<meta property="og:image" content="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062340513.png">
<meta property="article:published_time" content="2022-05-06T15:45:29.000Z">
<meta property="article:modified_time" content="2022-05-09T10:02:24.278Z">
<meta property="article:author" content="PhoenixDai">
<meta property="article:tag" content="MNER">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062241917.png">

<link rel="canonical" href="http://example.com/2022/05/06/%E9%98%85%E8%AF%BB%E3%80%8ASource-of-Transfer-in-Multilingual-NER%E3%80%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>阅读《Sources of Transfer in Multilingual NER》 | Sycamore</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Sycamore</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Phoenix reborns from the ashe</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/06/%E9%98%85%E8%AF%BB%E3%80%8ASource-of-Transfer-in-Multilingual-NER%E3%80%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/Phoenix-Logo-White.png">
      <meta itemprop="name" content="PhoenixDai">
      <meta itemprop="description" content="Anything that doesn't kill me makes me stronger">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sycamore">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          阅读《Sources of Transfer in Multilingual NER》
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-05-06 23:45:29" itemprop="dateCreated datePublished" datetime="2022-05-06T23:45:29+08:00">2022-05-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-05-09 18:02:24" itemprop="dateModified" datetime="2022-05-09T18:02:24+08:00">2022-05-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Wenge/" itemprop="url" rel="index"><span itemprop="name">Wenge</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>Mueller, David, Nicholas Andrews, and Mark Dredze. "Sources of transfer in multilingual named entity recognition." <em>arXiv preprint arXiv:2005.00847</em> (2020).</p>
</blockquote>
<p>命名实体本质上是多语言的，任何给定语言的注释都可能受到限制。这促使我们考虑多语言命名实体识别 (NER)，其中一个模型使用从一种以上语言中提取的注释数据进行训练。然而，这个简单想法的直接实现在实践中并不总是有效：<strong>尽管可以访问更多的训练数据，但使用从多种语言中提取的注释数据对 NER 模型的朴素训练始终低于仅在单语数据上训练的模型。</strong></p>
<p>本文的出发点是对这个问题的一个简单解决方案，其中通过在多语种模型的单语数据上进行微调，来始终如一地优于单语模型。为了解释这种现象，我们探索了多语言 NER 模型中多语言迁移的来源，并比较了多语言模型与单语言模型的权重结构。我们发现多语言模型有效地跨语言共享许多参数，并且微调可能会利用大量这些参数。</p>
<p><span id="more"></span></p>
<h4 id="文章贡献">文章贡献</h4>
<p>我们的第一个贡献是一种技术，<strong>通过对单语数据进行微调，可以使多语言NER模型适应目标语言。</strong>在神经机器翻译中，已经探索了一种类似的转移持续训练方法，用于领域适应；我们表明，它可以与NER的多语言模型一起工作，在单语baseline上提高性能达3倍的F1参数。</p>
<p>我们的第二个贡献是通过对 NER 多语言模型的广泛实证研究，解释了这种技术的有效性。我们比较了几种类型的神经 NER 模型，包括三个字符（或字节）级架构，并评估跨小和大语言集的迁移。特别是，我们发现：</p>
<ol type="1">
<li><p>除了 Byte-to-Span (BTS)，大多数 NER 架构都没有从多语言训练中受益。 尽管如此，比 BTS 更简单的模型，具有更多的归纳偏置，在单语和多语种设置中都可以胜过 BTS。</p>
<blockquote>
<p>归纳偏置可以理解为，从现实生活中观察到的现象中归纳出一定的规则，然后对模型做一定的约束，从而可以起到“模型选择”的作用，即从假设空间中选择出更符合现实规则的模型。<strong>褒义词</strong></p>
</blockquote></li>
<li><p>多语言模型比单语模型更有效，因为对于给定的性能水平，它们需要的参数要少得多。 这表明许多参数是跨语言共享的。</p></li>
<li><p>多语言权重转移到看不见的语言，结果好坏参半。特别是，当多语言训练集中存在高度词汇重叠或密切相关的语言时，可能会发生迁移。</p></li>
<li><p>在多语言模型中，语言之间共享大量重要参数，微调可以利用这些参数来增强其性能。</p></li>
</ol>
<h2 id="预知识">预知识</h2>
<h3 id="crf">CRF</h3>
<p>CRF，全称 Conditional Random Fields，中文名：条件随机场。</p>
<h4 id="什么时候用crf">什么时候用CRF</h4>
<p>当输出序列的每一个位置的状态，需要考虑到<em>相邻位置</em>的状态的时候。举两个例子：</p>
<ol type="1">
<li>假设有一堆小明日常生活的照片，可能的状态有吃饭、洗澡、刷牙等，大部分情况，我们是能够识别出小明的状态的，但是如果你看到一张小明露出牙齿的照片，在没有相邻的小明的状态为条件的情况下，是很难判断他是在吃饭还是刷牙的。这时，就可以用CRF。</li>
<li>假设有一句话，这里假设是英文，我们要判断每个词的词性，那么对于一些词来说，如果不知道相邻词的词性的情况下，是很难准确判断每个词的词性的。这时，也可以用CRF。</li>
</ol>
<h4 id="什么是随机场">什么是随机场</h4>
<p>随机变量的集合称为随机过程。由一个空间变量索引的随机过程，称为随机场。</p>
<p>一组随机变量按照某种概率分布随机赋值到某个空间的一组位置上时，这些赋予了随机变量的位置就是一个随机场。</p>
<p>比如上面的例子中，小明的一系列照片分别是：什么状态组成了一组位置，我们从一组随机变量{吃饭、洗澡、刷牙}中取值，随机变量遵循某种概率分布，随机赋给一组照片的某一张的输出位置，并完成这组照片的所有输出位置的状态赋值后，这些状态和所在的位置全体称为随机场。</p>
<h4 id="为什么叫条件随机场">为什么叫条件随机场</h4>
<p><strong>马尔可夫随机场：</strong></p>
<p>如果一个位置的赋值只和与它相邻的位置的值有关，与和它不相邻的位置的值无关，那么这个随机场就是一个马尔可夫随机场。</p>
<p>这个假设用在小明和词性标注的例子中的话就是我们是通过前一张照片或者后一张照片的状态来判断当前照片的状态是刷牙还是吃饭，我们是根据前一个词的词性或者后一个词的词性来判断当前词的词性是什么。</p>
<p><strong>条件随机场(CRF)：</strong></p>
<p>给定了一组观测状态(照片可能的状态/可能出现的词)下的马尔可夫随机场。</p>
<p><strong>CRF考虑到了观测状态这个<u>先验条件</u></strong></p>
<h4 id="crf如何提取特征">CRF如何提取特征</h4>
<p>CRF中有两类特征函数，分别是状态特征和转移特征</p>
<p>​ 状态特征用当前节点(某个输出位置可能的状态中的某个状态称为一个节点)的状态分数表示</p>
<p>​ 转移特征用上一个节点到当前节点的转移分数表示。</p>
<p><strong>损失函数：</strong> <span class="math display">\[
LossFunction = \frac{P_{RealPath}}{P_1+P_2+...+P_N}
\]</span> <span class="math inline">\(P_{RealPath}\)</span>表示真实路径分数(包括状态分数和转移分数)，<span class="math inline">\(P_i\)</span>表示其他所有可能的路径的分数(包括状态分数和转移分数)。</p>
<p>这里的路径用词性来举例就是一句话对应的词性序列，真实路径表示真实的词性序列，其他可能的路径表示其他的词性序列。</p>
<hr />
<p>对于词性标注来说，给定一句话和其对应的词性序列，那么其似然性的计算公式：</p>
<p><img src="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062241917.png" /></p>
<ul>
<li><span class="math inline">\(l\)</span>表示某个词上定义的状态特征的个数，<span class="math inline">\(k\)</span>表示转移特征的个数，<span class="math inline">\(i\)</span>表示词在句子中的位置。</li>
<li><strong><span class="math inline">\(t_k\)</span>和<span class="math inline">\(s_l\)</span>分别是转移特征函数和状态特征函数。</strong></li>
<li><span class="math inline">\(λ_k\)</span>和<span class="math inline">\(μ_l\)</span>分别是转移特征函数和状态特征函数的权重系数，通过最大似然估计可以得到。</li>
<li>上面提到的状态分数和转移分数都是非规范化的对数概率，所以概率计算都是加法，这里加上一个exp是为了将对数概率转为正常概率。实际计算时还会除以一个规范化因子<span class="math inline">\(Z(x)\)</span>，其实就是一个softmax过程。</li>
</ul>
<p>在只有CRF的情况下，上面说的两类特征函数都是人工设定好的：人工设定了观测序列的特征</p>
<ul>
<li><p>人为设定状态特征模板，比如设定“某个词是名词”等。</p></li>
<li><p>人为设定转移特征模板，比如设定“某个词是名词时，上一个词是形容词”等。</p></li>
</ul>
<p>给定一句话的时候，就根据上面设定的特征模板来计算这句话的特征分数，计算的时候，如果这句话符合特征模板中的特征规则，则那个特征规则的值就为1，否则就为0。</p>
<p><kbd>所以如果我们能使用深度神经网络的方式，特征就可以由模型自己学习得到，这就是使用BERT+CRF的原因。</kbd></p>
<h4 id="命名实体识别中的bert和crf是怎么配合的">命名实体识别中的BERT和CRF是怎么配合的</h4>
<p>由BERT学习序列的状态特征（实体标注），从而得到一个状态分数（每个可能的状态的softmax前的概率），该分数直接输入到CRF层，省去了人工设置状态特征模板。</p>
<p><strong>实体标注</strong>：</p>
<p>​ 通常用<span class="math inline">\(BIO\)</span>标注，<span class="math inline">\(B\)</span>表示词的开始，<span class="math inline">\(I\)</span>表示词的延续，<span class="math inline">\(O\)</span>表示非实体词</p>
<p>​ 比如我们要识别人名和地点</p>
<table>
<thead>
<tr class="header">
<th>小</th>
<th>明</th>
<th>爱</th>
<th>北</th>
<th>京</th>
<th>的</th>
<th>天</th>
<th>安</th>
<th>门</th>
<th>。</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>B-Person</td>
<td>I-Person</td>
<td>O</td>
<td>B-Location</td>
<td>I-Location</td>
<td>O</td>
<td>B-Location</td>
<td>I-Location</td>
<td>I-Location</td>
<td>O</td>
</tr>
</tbody>
</table>
<p>BERT层学到了句子中每个字符最可能对应的实体标注是什么，这个过程是考虑到了每个字符左边和右边的上下文信息的，但是输出的最大分数对应的实体标注依然可能有误，不会100%正确的。所以需要CRF</p>
<p>CRF需要的两个特征函数，其中状态特征函数BERT已经提供了，所以CRF需要特征转移函数（特征转移矩阵），该矩阵表示了所有标注状态之间的组合。</p>
<p>比如上述一共5个状态，加上START和END就是7种状态，那么这个矩阵就是一个<span class="math inline">\(7\times 7\)</span>的矩阵。这个矩阵一开始是随机初始化的，通过训练后慢慢会知道哪些组合更符合规则，哪些更不符合规则。</p>
<h3 id="viterbi维特比算法">Viterbi(维特比)算法</h3>
<p>举个例子：</p>
<table>
<thead>
<tr class="header">
<th>小</th>
<th>明</th>
<th>爱</th>
<th>北</th>
<th>京</th>
<th>。</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>B-Person</td>
<td>I-Person</td>
<td>O</td>
<td>O</td>
<td>O</td>
<td>O</td>
</tr>
</tbody>
</table>
<p>状态集合：<span class="math inline">\(\{B-P,I-P,O\}\)</span></p>
<p><img src="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062328986.png" style="zoom:50%;" /></p>
<p>首先，我们分别计算红、黄、蓝三个节点的输入连线的概率，以红色节点举例，我们先假设红色节点在最优路径上，那么输入到该节点的三条连线中，概率最大的那条一定在最优路径上，同理得出黄、蓝的连线。</p>
<p><img src="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062331071.png" style="zoom:50%;" /></p>
<p>最后递归获得所有的最优路线。由于就有三个起始状态，所以最后就有三条路径。</p>
<table>
<thead>
<tr class="header">
<th>路线1</th>
<th>B-P</th>
<th>I-P</th>
<th>O</th>
<th>O</th>
<th>O</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>路线2</strong></td>
<td><strong>B-P</strong></td>
<td><strong>O</strong></td>
<td><strong>I-P</strong></td>
<td><strong>B-P</strong></td>
<td><strong>I-P</strong></td>
</tr>
<tr class="even">
<td><strong>路线3</strong></td>
<td><strong>O</strong></td>
<td><strong>B-P</strong></td>
<td><strong>B-P</strong></td>
<td><strong>I-P</strong></td>
<td><strong>B-P</strong></td>
</tr>
</tbody>
</table>
<p>然后利用上文所提到的状态转移矩阵：</p>
<p><img src="https://raw.githubusercontent.com/ZimingDai/Picture/main/img/202205062340513.png" /></p>
<p>初始节点的概率计算为：<span class="math inline">\(Π(B-P) \times P(小|B-P)\)</span></p>
<p>迭代方式是：$ P_{上一层} P_{转移概率} P(明|B-P)$</p>
<p>最后选取概率最大的路径。</p>
<h2 id="model">Model</h2>
<h3 id="词级别crf">词级别CRF</h3>
<p>文章中的实现遵循了Lample的描述(<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.01360">Neural Architectures for Named Entity Recognition</a>)，并在此基础上提出了三种变体</p>
<p>前两个是字符级和字节级模型。多语言传输可能会发生在字节级表示中，作者感兴趣的是：当涉及更多不同的语言时，字符级是否会产生相似的结果。每个单词通过多层 BiLSTM 作为字符或字节序列生成单词级表示。词级表示输入句子级的BiLSTM后，它在每个时间步输出所有可能标签的 logits。然后将 logits 输入到 CRF 模型中，该模型经过训练以最大化”gold标签序列的对数似然性“。</p>
<p>该模型的第三个变体使用来自多语言 BERT (mBERT) 的上下文表示。 该模型与上述模型相似，主要区别在于词级表示是使用预训练的子词级 BERT 模型获得的，而不是从原始字符/字节构建的。 正如在原始 BERT 论文中所做的那样，我们将每个单词的第一个子词的表示视为该词的表示，并将该子词位置的最后 4 层输出串联起来作为我们的最终单词表示。</p>
<h3 id="charner">CharNER</h3>
<p>CharNER是一种深度神经序列标记体系结构，其在训练期间严格在字符级别上操作，但在推理期间使用词级别的边界。该模型在字符序列上运行5层BiLSTM，并经过训练以预测序列中每个字符的NER标签。在推理过程中，具有未经训练的过渡参数的Viterbi解码器在每个单词上强制执行一致的字符级别标签；获得单词级别的BIO标签不需要启发式方法和很少的后处理。</p>
<h3 id="bts">BTS</h3>
<p>BTS是一种在字节序列上操作的seq2seq模型。输入包括了一个UFT-8字节的窗口，输出是一个带有充足统计信息的序列，这些信息是在输入序列中出现的标记实体跨度</p>
<p>因为字节序列很长，BTS 在 60 字节的滑动窗口上运行，独立处理每个段； 模型的整个上下文总是限制在 60 字节。</p>
<h2 id="试验结论">试验结论</h2>
<p>尽管使用了4倍或10倍的标记数据，但Polyglot-NER模型未能比单语模型有所改善。语言之间标签优先级的差异本身并不能解释这一点。</p>
<p>多语言模型实际上从观察多种语言中学到了更多，并且这些信息可以转移到每种语言。 此外，在不观察其他语言的情况下，使用标准训练目标可能无法实现单语模型的理想最优值； 我们发现更多的正则化对单语模型没有帮助。 然而，朴素联合优化所有语言可能会提供过于具有挑战性的优化环境，无法同时获得每种语言的最优值。</p>
<p>多语言参数到看不见的语言的可迁移性取决于多种因素。推测这些因素部分与原始多语言训练集中的语言相关性有关。</p>
<h2 id="polyglot模型">Polyglot模型</h2>
<h3 id="错误分析">错误分析</h3>
<p>多种语言模型倾向于在O型标签上犯更多的错误，这表明有<strong>产生精度错误的趋势</strong>，但微调倾向于纠正这一趋势，回到单语性能。我们还发现，与单语模型相比，微调模型的PER和ORG标签更加出色。然而，多语言LORELEI模型并非如此，这表明这种转移来自多种语言和微调训练的结合。</p>
<p>多语言微调模型可能比单语模型表现更好的一个原因<strong>是它们在训练期间看到的实体数量更多。</strong> 许多语言在其验证集中包含实体，这些实体出现在其他语言的训练集中。 我们将此类“常见实体”识别为语言<span class="math inline">\(l\)</span>的验证集中的实体，它们共享某种程度的表面形式重叠并出现在语言<span class="math inline">\(l’ \neq l\)</span>的训练集中的实体类型。</p>
<p>发现多语言模型在“常见实体”上的错误率较低 ”，这表明这些实体是多语言 NER 中的迁移来源。 并且特定于语言的微调往往会增加错误率，这要么是由于遗忘，要么只是因为在微调期间减少了“非常见实体”上的错误。</p>
<hr />
<p>神经网络需要大量的参数，但是并不是所有的参数都需要对目标函数进行建模。假设学习语言<span class="math inline">\(l\)</span>的单语言NER模型需要<span class="math inline">\(M^l\)</span>个参数，那么学习对多种语言<span class="math inline">\(L\)</span>建立单语言模型，则需要<span class="math inline">\(M&#39;=\sum_{l\in L}^l\)</span>个参数，因为单语言模型之间参数不会共享。在这种情况下，多语言学习的负面结果可以通过模型的参数化不足来解释。相反，本模型可以跨多种语言共享参数，从而有效地学习跨语言表示。在这种情况下，我们预计模型需要的参数比<span class="math inline">\(M&#39;\)</span>少得多，并且跨语言过度共享参数可以解释多语言性能不佳的原因。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/MNER/" rel="tag"># MNER</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/05/06/%E9%98%85%E8%AF%BB%E3%80%8AA-Survey-on-Deep-Learning-for-NER%E3%80%8B/" rel="prev" title="阅读《A Survey on Deep Learning for NER》">
      <i class="fa fa-chevron-left"></i> 阅读《A Survey on Deep Learning for NER》
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E7%AB%A0%E8%B4%A1%E7%8C%AE"><span class="nav-number">1.</span> <span class="nav-text">文章贡献</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E7%9F%A5%E8%AF%86"><span class="nav-number"></span> <span class="nav-text">预知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#crf"><span class="nav-number"></span> <span class="nav-text">CRF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E7%94%A8crf"><span class="nav-number">1.</span> <span class="nav-text">什么时候用CRF</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%9A%8F%E6%9C%BA%E5%9C%BA"><span class="nav-number">2.</span> <span class="nav-text">什么是随机场</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AB%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA"><span class="nav-number">3.</span> <span class="nav-text">为什么叫条件随机场</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#crf%E5%A6%82%E4%BD%95%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81"><span class="nav-number">4.</span> <span class="nav-text">CRF如何提取特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84bert%E5%92%8Ccrf%E6%98%AF%E6%80%8E%E4%B9%88%E9%85%8D%E5%90%88%E7%9A%84"><span class="nav-number">5.</span> <span class="nav-text">命名实体识别中的BERT和CRF是怎么配合的</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#viterbi%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95"><span class="nav-number"></span> <span class="nav-text">Viterbi(维特比)算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model"><span class="nav-number"></span> <span class="nav-text">Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%8D%E7%BA%A7%E5%88%ABcrf"><span class="nav-number"></span> <span class="nav-text">词级别CRF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#charner"><span class="nav-number"></span> <span class="nav-text">CharNER</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bts"><span class="nav-number"></span> <span class="nav-text">BTS</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%95%E9%AA%8C%E7%BB%93%E8%AE%BA"><span class="nav-number"></span> <span class="nav-text">试验结论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#polyglot%E6%A8%A1%E5%9E%8B"><span class="nav-number"></span> <span class="nav-text">Polyglot模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%94%99%E8%AF%AF%E5%88%86%E6%9E%90"><span class="nav-number"></span> <span class="nav-text">错误分析</span></a></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="PhoenixDai"
      src="/images/Phoenix-Logo-White.png">
  <p class="site-author-name" itemprop="name">PhoenixDai</p>
  <div class="site-description" itemprop="description">Anything that doesn't kill me makes me stronger</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2022-01 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PhoenixDai</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='48,0,65' opacity='0.9' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>


  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
